## Environment Configuration File

# Secrets
HF_TOKEN=""

## Local Environment Configuration
SERVER_BASE_URL=localhost

# Paths
PROJECT_DIR=${HOME}/verifact
# Source Data Directories
DATA_DIR=${PROJECT_DIR}/data
PHYSIONET_DIR=${DATA_DIR}/physionet.org
MIMIC3_DIR=${DATA_DIR}/physionet.org/files/mimiciii/1.4
DATASET_DIR=${DATA_DIR}/dataset
ANNOTATED_DATASET_DIR=${DATA_DIR}/physionet.org/files/verifact-bhc/1.0

# Ingested Data Directories
STORAGE_DIR=${PROJECT_DIR}/storage
QDRANT_STORAGE_PATH=${STORAGE_DIR}/qdrant
REDIS_STORAGE_PATH=${STORAGE_DIR}/redis

# Qdrant Collection Names
MIMIC3_EHR_COLLECTION_NAME=ehr_noteevents
MIMIC3_HC_COLLECTION_NAME=bhc_noteevents
MIMIC3_LLM_HC_COLLECTION_NAME=llm_bhc_noteevents

# HuggingFace Configs
TOKENIZERS_PARALLELISM=false

## Docker & Traefik Configuration

# Service Hosts, Ports, URLs
TRAEFIK_HOST=traefik.localhost
TRAEFIK_CONTAINER_PORT=8080
TRAEFIK_HOST_PORT=8090
TRAEFIK_URL=http://${TRAEFIK_HOST}:${TRAEFIK_CONTAINER_PORT}/
TRAEFIK_DASHBOARD_URL=http://${TRAEFIK_HOST}:${TRAEFIK_HOST_PORT}/dashboard/

LLM_HOST=llm.localhost
LLM_CONTAINER_PORT=8000
LLM0_HOST_PORT=8100
LLM1_HOST_PORT=8101
LLM2_HOST_PORT=8102
LLM3_HOST_PORT=8103
LLM_URL_BASE=http://${LLM_HOST}/v1/
LLM_URL=http://${LLM_HOST}/v1/

EMBED_HOST=embed.localhost
EMBED_CONTAINER_PORT=7997
EMBED0_HOST_PORT=8110
EMBED1_HOST_PORT=8111
EMBED2_HOST_PORT=8112
EMBED3_HOST_PORT=8113
EMBED_URL_BASE=http://${EMBED_HOST}/v1
EMBED_URL=http://${EMBED_HOST}/v1/embeddings/

RERANK_HOST=rerank.localhost
RERANK_CONTAINER_PORT=7997
RERANK0_HOST_PORT=8120
RERANK1_HOST_PORT=8121
RERANK2_HOST_PORT=8122
RERANK3_HOST_PORT=8123
RERANK_URL_BASE=http://${RERANK_HOST}/v1
RERANK_URL=http://${RERANK_HOST}/v1/rerank/

REDIS_HOST=redis.localhost
REDIS_CONTAINER_PORT=6379
REDIS_HOST_PORT=6379
REDIS_URL=redis://${REDIS_HOST}:${REDIS_HOST_PORT}/
REDIS_DASHBOARD_CONTAINER_PORT=8001
REDIS_DASHBOARD_HOST_PORT=6380
REDIS_DASHBOARD_URL=http://${REDIS_HOST}:${REDIS_DASHBOARD_HOST_PORT}/

RQ_DASHBOARD_HOST=rq-dashboard.localhost
RQ_DASHBOARD_CONTAINER_PORT=9181
RQ_DASHBOARD_HOST_PORT=9181
RQ_DASHBOARD_URL=http://${RQ_DASHBOARD_HOST}:${RQ_DASHBOARD_HOST_PORT}/

QDRANT_HOST=qdrant.localhost
QDRANT_CONTAINER_PORT=6333
QDRANT_HOST_PORT=6333
QDRANT_GRPC_CONTAINER_PORT=6334
QDRANT_GRPC_HOST_PORT=6334
QDRANT_URL=http://${QDRANT_HOST}:${QDRANT_HOST_PORT}/
QDRANT_DASHBOARD_URL=http://${QDRANT_HOST}:${QDRANT_HOST_PORT}/dashboard/

## Prometheus & Grafana
MONITORING_CONFIG_DIR=${PROJECT_DIR}/services/vllm/monitoring
PROMETHEUS_CONTAINER_PORT=9090
PROMETHEUS_HOST_PORT=9090

GRAFANA_CONTAINER_PORT=3000
GRAFANA_HOST_PORT=3000

## Docker Environment
# Traefik settings
ADMIN_EMAIL=email@domain.edu # e.g. ADMIN_EMAIL=admin@website.com
DOMAIN=localhost # e.g. DOMAIN=website.com
CERT_RESOLVER= #letsencrypt # keep it blank for internal private or local net
TRAEFIK_USER=admin
TRAEFIK_PASSWORD_HASH=verifact

# Embed Model
EMBED_MODEL_NAME=BAAI/bge-m3

# Rerank Model
RERANK_MODEL_NAME=BAAI/bge-reranker-v2-m3

# vLLM settings (https://docs.vllm.ai/en/latest/models/engine_args.html)
# Default settings here: https://github.com/vllm-project/vllm/blob/main/vllm/engine/arg_utils.py#L68
LLM_MODEL_NAME=hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4
TOKENIZER_MODEL_NAME=meta-llama/Meta-Llama-3.1-70B-Instruct # Same as LLM_MODEL_NAME unless separate quantized model
DTYPE=auto # NOTE: Use float16 if quantized; otherwise use bfloat16
LLM_MAX_MODEL_LEN=8500
GPU_MEMORY_UTILIZATION=0.8
GPU0_MEMORY_UTILIZATION=${GPU_MEMORY_UTILIZATION}
GPU1_MEMORY_UTILIZATION=${GPU_MEMORY_UTILIZATION}
GPU2_MEMORY_UTILIZATION=${GPU_MEMORY_UTILIZATION}
GPU3_MEMORY_UTILIZATION=${GPU_MEMORY_UTILIZATION}
TENSOR_PARALLEL_SIZE=1
PIPELINE_PARALLEL_SIZE=1
BLOCK_SIZE=16
SWAP_SPACE=4 # GiB
GUIDED_DECODING_BACKEND=outlines
EXTRA_ARGS="--quantization=awq --enforce-eager --enable-prefix-caching"
# NOTE: disable default quantization=marlin-awq because it is currently unstable for Llama 3.1: https://github.com/vllm-project/vllm/issues/7726
