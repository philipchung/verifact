"""Llama-Index Embedding wrapper around BGE-M3 FlagEmbedding Service

This is based on llama_index.embeddings.huggingface.HuggingFaceEmbedding
(https://github.com/run-llama/llama_index/blob/main/llama_index/embeddings/huggingface.py),
but is customized for BAAI/BGE-M3 Embeddings which generate multiple vector
embeddings simultaneously: https://huggingface.co/BAAI/bge-m3.

BGE-M3 generates dense, sparse, and colbert embeddings all at once and the default
scoring method is to average the embeddings. In order to store each embedding separately
in a vector database, we return each embedding vector.
"""

import warnings
from typing import TYPE_CHECKING, Any

import httpx
from llama_index.core.bridge.pydantic import Field
from llama_index.core.schema import MetadataMode

from rag.embedding.base import BaseEmbedding
from rag.embedding.utils import NamedEmbedding
from rag.schema.base_node import EmbeddingItem
from rag.schema.node_schema import TextNode

if TYPE_CHECKING:
    pass

DEFAULT_BGE_M3_LENGTH = 8192


class M3Embedding(BaseEmbedding):
    """Llama-Index wrapper around API to M3 Embedding model.

    This implementation makes API calls to an embedding API endpoint to generate embeddings
    and is appropriate for async pipelines.  The embedding API endpoint should be configured
    and launched prior to calling methods in this class.

    NOTE: `model_name` init arguments has no effect.
    `embed_batch_size` is a client-side batch limit, while the actual batch size throughput
    is configured on the server side.  The context length accepted by the inference model
    is also configured on the server side.
    """

    model_name: str = Field(default="BAAI/bge-m3", description="Model name.")
    embed_batch_size: int = Field(default=50, description="Embedding batch size.", gt=0)
    api_base: str = Field(default="http://embed.localhost/v1", description="API base URL.")
    return_dense: bool = Field(default=True, description="Return dense embeddings.")
    return_sparse: bool = Field(default=True, description="Return sparse lexical embeddings.")
    return_colbert: bool = Field(default=False, description="Return ColBERT embeddings.")
    dense_name: str = Field(
        default="dense",
        description="Vector name key for dense embeddings stored in "
        "node's `embeddings` dict attribute.",
    )
    sparse_name: str = Field(
        default="sparse",
        description="Vector name key for sparse embeddings stored in "
        "node's `embeddings` dict attribute.",
    )
    colbert_name: str = Field(
        default="colbert",
        description="Vector name key for ColBERT embeddings stored in "
        "node's `embeddings` dict attribute.",
    )
    default_vector_name: str = Field(
        default="dense",
        description="Default vector name from `embeddings` dict attribute which "
        "contains embedding that is stored in node's `embedding` attribute.",
    )
    timeout: float | None = Field(default=600.0, description="Timeout for API calls.")
    num_retries: int = Field(default=5, description="Number of retries for API calls.")
    metadata_mode: MetadataMode | str = Field(
        default=MetadataMode.EMBED,
        description="Metadata mode to format document with prior to computing score."
        "'none' means to only use text. "
        "'embed' and 'llm' uses text and metadata based on embed and llm metadata filters. "
        "'all' uses all text and metadata.",
    )
    num_workers: int | None = Field(
        default=4,
        description="The number of workers to use for async embedding calls.",
    )

    @classmethod
    def class_name(cls) -> str:
        return "M3Embedding"

    def _embed(self, sentences: list[str], **kwargs) -> list[NamedEmbedding]:
        """Embed sentences ("dense", "sparse", "colbert" embeddings for each sentences)."""
        num_retries = kwargs.pop("num_retries", self.num_retries)
        if num_retries == 0:
            raise ConnectionError(
                f"Failed to generate embeddings after {self.num_retries} retries."
            )

        # Embedding for each sentence is a dict with keys: "dense", "sparse", "colbert"
        # that correspond to the 3 types of embeddings generated by the M3 model.
        response = httpx.request(
            method="POST",
            url=self.api_base.rstrip("/") + "/embeddings",
            json={"input": sentences, "model": self.model_name, "user": "user"},
            timeout=self.timeout,
        )

        if response.is_success:
            payload_list = response.json()["data"]
            embeddings: list[dict[str, Any]] = [x["embedding"] for x in payload_list]

            # Reformat each embedding; wrap in EmbeddingItem with name and kind
            out_embeddings: list[dict[str, EmbeddingItem]] = []
            for e in embeddings:
                out_embedding = {}
                if self.return_dense:
                    out_embedding[self.dense_name] = EmbeddingItem(
                        name=self.dense_name, embedding=e.pop("dense"), kind="dense"
                    )
                if self.return_sparse:
                    out_embedding[self.sparse_name] = EmbeddingItem(
                        name=self.sparse_name, embedding=e.pop("sparse"), kind="sparse"
                    )
                if self.return_colbert:
                    out_embedding[self.colbert_name] = EmbeddingItem(
                        name=self.colbert_name,
                        embedding=e.pop("colbert"),
                        kind="colbert",
                    )
                out_embeddings.append(out_embedding)
            return out_embeddings
        else:
            # Retry if embedding did not succeed
            return self._embed(sentences=sentences, num_retries=num_retries - 1)

    # To get query embedding get_query_embedding() defined on BaseEmbedding parent class

    def _get_query_embedding(self, query: str) -> NamedEmbedding:
        """Get query embedding."""
        return self._embed([query])[0]

    async def _aget_query_embedding(self, query: str) -> NamedEmbedding:
        """Get query embedding async."""
        return self._get_query_embedding(query)

    async def _aget_text_embedding(self, text: str) -> NamedEmbedding:
        """Get text embedding async."""
        return self._get_text_embedding(text)

    def _get_text_embedding(self, text: str) -> NamedEmbedding:
        """Get text embedding."""
        return self._get_text_embeddings([text])[0]

    # To get single embedding get_text_embedding() defined on BaseEmbedding parent class

    def _get_text_embeddings(self, texts: list[str]) -> list[NamedEmbedding]:
        """Get text embeddings."""
        return self._embed(texts)

    def get_text_embeddings(self, texts: list[str]) -> list[NamedEmbedding]:
        "Get embeddings for list of string text."
        return self._get_text_embeddings(texts)

    def __call__(self, nodes: list[TextNode], **kwargs: Any) -> list[TextNode]:
        "Compute embeddings for node content."
        metadata_mode = kwargs.pop("metadata_mode", self.metadata_mode)
        # Create Embeddings
        embeddings: list[dict[str, Any]] = self.get_text_embedding_batch(
            [node.get_content(metadata_mode=metadata_mode) for node in nodes], **kwargs
        )
        # Associate Embeddings to Nodes
        nodes = self._associate_nodes_and_embeddings(nodes, embeddings)
        return nodes

    async def acall(self, nodes: list[TextNode], **kwargs: Any) -> list[TextNode]:
        "Async version for compute embeddings for node content."
        metadata_mode = kwargs.pop("metadata_mode", self.metadata_mode)
        # Create Embeddings
        embeddings = await self.aget_text_embedding_batch(
            [node.get_content(metadata_mode=metadata_mode) for node in nodes], **kwargs
        )
        # Associate Embeddings to Nodes
        nodes = self._associate_nodes_and_embeddings(nodes, embeddings)
        return nodes

    def _associate_nodes_and_embeddings(
        self, nodes: list[TextNode], embeddings: list[Any]
    ) -> list[TextNode]:
        "Associate Embeddings to Nodes."
        for node, embedding in zip(nodes, embeddings, strict=False):
            try:
                node.set_embeddings(embeddings=embedding, default=self.default_vector_name)
            except Exception:
                warnings.warn(
                    "No method `set_embedding`, falling back to setting `embedding` attribute.",
                    stacklevel=1,
                )
                node.embedding = embedding
        return nodes
